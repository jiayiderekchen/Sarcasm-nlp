{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reddit_multi_input_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyODBB/xK/qFL2vUTAuk+Vju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/Sarcasm-nlp/blob/master/reddit_multi_input_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEyCb5A6ZJPE",
        "colab_type": "code",
        "outputId": "2179281e-d29a-40b7-d54b-bda54ca20825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhD0ja60eRrW",
        "colab_type": "code",
        "outputId": "75db63c8-bd9f-424b-f21a-5931bc06a909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==2.1.0\n",
        "!pip install sentencepiece\n",
        "!pip install tensorflow-hub\n",
        "!pip install tensorflow-addons\n",
        "#!wget --quiet https://raw.githubusercontent.com/google-research/ALBERT/master/tokenization.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 27.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.1.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.17.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (45.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 6.5MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.17.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (45.2.0)\n",
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/f7/98c461ab7fcb4828f66a702f1af76811b9d3f47d62816f8cc57a9461b0da/tensorflow_addons-0.8.3-cp36-cp36m-manylinux2010_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 6.7MB/s \n",
            "\u001b[?25hCollecting typeguard\n",
            "  Downloading https://files.pythonhosted.org/packages/06/37/d236aec27f8a8eed66f1a17116eb51684528cf8005a6883f879fe2e842ae/typeguard-2.7.1-py3-none-any.whl\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.8.3 typeguard-2.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7gSHuuqaERd",
        "colab_type": "code",
        "outputId": "b94ad072-f3ba-4e63-eb63-b5299c41a83a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/dataset/sarcasm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset/sarcasm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9gGhXLcaW2Y",
        "colab_type": "code",
        "outputId": "60669c80-2e62-4617-8526-e8827ce4661a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_gru.png\n",
            "\u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
            "sarcasm_detection_shared_task_reddit_testing.jsonl\n",
            "sarcasm_detection_shared_task_reddit_training.jsonl\n",
            "sarcasm_detection_shared_task_twitter_testing.jsonl\n",
            "sarcasm_detection_shared_task_twitter_training.jsonl\n",
            "tokenization.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_XH_TQ3f3dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsQon6CBaXdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reddit_train=pd.read_json('sarcasm_detection_shared_task_reddit_training.jsonl',lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYd47uZga3Z4",
        "colab_type": "code",
        "outputId": "65cfa5ff-0713-44c4-ac42-f34eba1d76b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "reddit_train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>Yeah I mean there's only one gender anyways, w...</td>\n",
              "      <td>[LPT: If you're worried about hurting someone'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>Sounds like you don't like science, you theist...</td>\n",
              "      <td>[Promotional images for some guy's Facebook pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>Ofc play them in try mode, Blizzard were so ge...</td>\n",
              "      <td>[My friends won't play Dota2; I won't play LoL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>I don't understand, Reddit told me that Hillar...</td>\n",
              "      <td>[Poll: Convention boosts Clinton to 11-point l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>yeh, they're the reigning triple premiers, why...</td>\n",
              "      <td>[Wayne Ludbey: Jordan Lewis has the ultimate c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                            context\n",
              "0  SARCASM  ...  [LPT: If you're worried about hurting someone'...\n",
              "1  SARCASM  ...  [Promotional images for some guy's Facebook pa...\n",
              "2  SARCASM  ...  [My friends won't play Dota2; I won't play LoL...\n",
              "3  SARCASM  ...  [Poll: Convention boosts Clinton to 11-point l...\n",
              "4  SARCASM  ...  [Wayne Ludbey: Jordan Lewis has the ultimate c...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9jeCHvobEHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reddit_train['response']=reddit_train['response'].str.replace('@USER', \"\") \n",
        "reddit_train['response']=reddit_train['response'].str.replace('\\d+', '')\n",
        "reddit_train['response']=reddit_train['response'].str.lower()\n",
        "reddit_train['response']=reddit_train['response'].str.replace('[^\\w\\s]','')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVRY4qxwckM7",
        "colab_type": "code",
        "outputId": "808de1e1-4488-474f-fb06-6fed6c021f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "reddit_train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>yeah i mean theres only one gender anyways wom...</td>\n",
              "      <td>[LPT: If you're worried about hurting someone'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>sounds like you dont like science you theist s...</td>\n",
              "      <td>[Promotional images for some guy's Facebook pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>ofc play them in try mode blizzard were so gen...</td>\n",
              "      <td>[My friends won't play Dota2; I won't play LoL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>i dont understand reddit told me that hillary ...</td>\n",
              "      <td>[Poll: Convention boosts Clinton to 11-point l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>yeh theyre the reigning triple premiers why br...</td>\n",
              "      <td>[Wayne Ludbey: Jordan Lewis has the ultimate c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                            context\n",
              "0  SARCASM  ...  [LPT: If you're worried about hurting someone'...\n",
              "1  SARCASM  ...  [Promotional images for some guy's Facebook pa...\n",
              "2  SARCASM  ...  [My friends won't play Dota2; I won't play LoL...\n",
              "3  SARCASM  ...  [Poll: Convention boosts Clinton to 11-point l...\n",
              "4  SARCASM  ...  [Wayne Ludbey: Jordan Lewis has the ultimate c...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09EVo02McTQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reddit_train['context']=reddit_train['context'].apply(lambda x: ','.join(map(str, x)))\n",
        "#reddit_train['context']=reddit_train['context'].str.replace('@USER', \"\") \n",
        "reddit_train['context']=reddit_train['context'].str.lower()\n",
        "reddit_train['context']=reddit_train['context'].str.replace('[^\\w\\s]','')\n",
        "reddit_train['context']=reddit_train['context'].str.replace('\\d+', '')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM581aywcU06",
        "colab_type": "code",
        "outputId": "019a5ead-3a63-4337-c740-b43d5daad189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "reddit_train.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>yeah i mean theres only one gender anyways wom...</td>\n",
              "      <td>lpt if youre worried about hurting someones fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>sounds like you dont like science you theist s...</td>\n",
              "      <td>promotional images for some guys facebook page...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>ofc play them in try mode blizzard were so gen...</td>\n",
              "      <td>my friends wont play dota i wont play lol is l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>i dont understand reddit told me that hillary ...</td>\n",
              "      <td>poll convention boosts clinton to point lead o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>yeh theyre the reigning triple premiers why br...</td>\n",
              "      <td>wayne ludbey jordan lewis has the ultimate com...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                            context\n",
              "0  SARCASM  ...  lpt if youre worried about hurting someones fe...\n",
              "1  SARCASM  ...  promotional images for some guys facebook page...\n",
              "2  SARCASM  ...  my friends wont play dota i wont play lol is l...\n",
              "3  SARCASM  ...  poll convention boosts clinton to point lead o...\n",
              "4  SARCASM  ...  wayne ludbey jordan lewis has the ultimate com...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAzapEnwcHPK",
        "colab_type": "code",
        "outputId": "73b3dfa6-4784-4c19-8406-457eca13b06e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(reddit_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOggGwl_tzyF",
        "colab_type": "code",
        "outputId": "46c6f114-f541-4753-aefb-66fc3fc1680a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from collections import Counter\n",
        "Counter(reddit_train['label'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'NOT_SARCASM': 2200, 'SARCASM': 2200})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPlJPrRQsUnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "train_label=le.fit_transform(reddit_train['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biiLuJCUJMQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yGAL4yBvOQo",
        "colab_type": "code",
        "outputId": "90d43b75-1221-4bfd-d5ff-ff4fcd945b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "reddit_test=pd.read_json('sarcasm_detection_shared_task_reddit_testing.jsonl',lines=True)\n",
        "reddit_test.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>response</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Dear Trump: the bill is now on your desk. Vet...</td>\n",
              "      <td>I was elected to golf not to uh, got nothing.</td>\n",
              "      <td>reddit_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Thailand cave rescue: All 12 boys, coach free...</td>\n",
              "      <td>I thought those kids were in a very bad spot. ...</td>\n",
              "      <td>reddit_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Snapchat: \"To attract more Android users, we ...</td>\n",
              "      <td>Nothing gives off that hipster, low budget, st...</td>\n",
              "      <td>reddit_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Nickelodeon just uploaded a high quality vers...</td>\n",
              "      <td>A major corporation would run a kickstarter so...</td>\n",
              "      <td>reddit_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Before you all start theorizing about Mats re...</td>\n",
              "      <td>Yup, scott “accidentally” added a last name to...</td>\n",
              "      <td>reddit_5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ...        id\n",
              "0  [Dear Trump: the bill is now on your desk. Vet...  ...  reddit_1\n",
              "1  [Thailand cave rescue: All 12 boys, coach free...  ...  reddit_2\n",
              "2  [Snapchat: \"To attract more Android users, we ...  ...  reddit_3\n",
              "3  [Nickelodeon just uploaded a high quality vers...  ...  reddit_4\n",
              "4  [Before you all start theorizing about Mats re...  ...  reddit_5\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0QlWiTlvblr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reddit_test['response']=reddit_test['response'].str.replace('@USER', \"\") \n",
        "reddit_test['response']=reddit_test['response'].str.replace('\\d+', '')\n",
        "reddit_test['response']=reddit_test['response'].str.lower()\n",
        "reddit_test['response']=reddit_test['response'].str.replace('[^\\w\\s]','')\n",
        "reddit_test['context']=reddit_test['context'].apply(lambda x: ','.join(map(str, x)))\n",
        "#reddit_test['context']=reddit_test['context'].str.replace('@USER', \"\") \n",
        "reddit_test['context']=reddit_test['context'].str.lower()\n",
        "reddit_test['context']=reddit_test['context'].str.replace('[^\\w\\s]','')\n",
        "reddit_test['context']=reddit_test['context'].str.replace('\\d+', '')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDjQfkKFvmKE",
        "colab_type": "code",
        "outputId": "d8bed9ef-ab6e-4675-edf7-ab29c5e4cb93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "reddit_test.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>response</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dear trump the bill is now on your desk veto t...</td>\n",
              "      <td>i was elected to golf not to uh got nothing</td>\n",
              "      <td>reddit_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thailand cave rescue all  boys coach freed lat...</td>\n",
              "      <td>i thought those kids were in a very bad spot t...</td>\n",
              "      <td>reddit_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>snapchat to attract more android users we are ...</td>\n",
              "      <td>nothing gives off that hipster low budget star...</td>\n",
              "      <td>reddit_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nickelodeon just uploaded a high quality versi...</td>\n",
              "      <td>a major corporation would run a kickstarter so...</td>\n",
              "      <td>reddit_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>before you all start theorizing about mats rec...</td>\n",
              "      <td>yup scott accidentally added a last name to a ...</td>\n",
              "      <td>reddit_5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ...        id\n",
              "0  dear trump the bill is now on your desk veto t...  ...  reddit_1\n",
              "1  thailand cave rescue all  boys coach freed lat...  ...  reddit_2\n",
              "2  snapchat to attract more android users we are ...  ...  reddit_3\n",
              "3  nickelodeon just uploaded a high quality versi...  ...  reddit_4\n",
              "4  before you all start theorizing about mats rec...  ...  reddit_5\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq6ibth_et3B",
        "colab_type": "text"
      },
      "source": [
        "#BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKg0eLmGfIgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTY8IMwEeuHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YloclZrLfKGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tokenization\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmshsKHZfQfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_response = bert_encode(reddit_train.response, tokenizer, max_len=200)\n",
        "train_context = bert_encode(reddit_train.context, tokenizer, max_len=200)\n",
        "train_labels=reddit_train.label.values\n",
        "#test_input = bert_encode(test_bert.values, tokenizer, max_len=160)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuY1n_7FJQFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwNIe3UVvZJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_response = bert_encode(reddit_test.response, tokenizer, max_len=200)\n",
        "test_context = bert_encode(reddit_test.context, tokenizer, max_len=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Kik3pDvylj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen=[test_context[0],test_context[1],test_context[2],test_response[0],test_response[1],test_response[2]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VJSYpA7fByZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " max_len=200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epLdmX34iQBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,concatenate,Dense,GlobalAveragePooling1D,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4XStaKfX_jM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "step = tf.Variable(0, trainable=False)\n",
        "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    [10000, 15000], [1e-0, 1e-1, 1e-2])\n",
        "# lr and wd can be a function or a tensor\n",
        "lr = 1e-1 * schedule(step)\n",
        "wd = lambda: 1e-4 * schedule(step)\n",
        "\n",
        "# ...\n",
        "\n",
        "optimizer = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dunR1CHuexd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contex_input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"contex_input_word_ids\")\n",
        "contex_input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"contex_input_mask\")\n",
        "contex_segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"contex_segment_ids\")\n",
        "_, context_sequence_output = bert_layer([contex_input_word_ids, contex_input_mask, contex_segment_ids])\n",
        "context_clf_output = context_sequence_output[:, 0, :]\n",
        "\n",
        "\n",
        "reponse_input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_input_word_ids\")\n",
        "reponse_input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_input_mask\")\n",
        "reponse_segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_segment_ids\")\n",
        "_, reponset_sequence_output = bert_layer([reponse_input_word_ids, reponse_input_mask, reponse_segment_ids])\n",
        "reponset_clf_output = reponset_sequence_output[:, 0, :]\n",
        "\n",
        "\n",
        "\n",
        "conc=concatenate([context_clf_output,reponset_clf_output])\n",
        "conc=Dropout(0.3)(conc)\n",
        "out = Dense(1, activation='sigmoid')(conc)\n",
        "    \n",
        "model = Model(inputs=[contex_input_word_ids, contex_input_mask, contex_segment_ids,reponse_input_word_ids,reponse_input_mask,reponse_segment_ids], outputs=out)\n",
        "model.compile(Adam(1e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJKok855k0F3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen=[train_context[0],train_context[1],train_context[2],train_response[0],train_response[1],train_response[2]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlq0hdlXKBUC",
        "colab_type": "code",
        "outputId": "72554cd1-bcb0-4998-cb28-c934d21a8d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_gen),len(train_label)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 4400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf6e6w0nMTbu",
        "colab_type": "code",
        "outputId": "1422985e-3fd1-4d92-bd66-9a603dec28f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_context[0].shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4400, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu3g2_VNIfwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_addons as tfa\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfyQCuF6LxQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unpack(a, b, c, d,e,f,g): \n",
        "    #print(a[g].shape, b[g].shape, c[g].shape, d[g].shape,e[g].shape,f[g].shape) \n",
        "    return [a[g], b[g], c[g], d[g],e[g],f[g]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuqQzXKYPIdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unpack(*train_gen,train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN_y6uqgX3pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ijzrJELIq5A",
        "colab_type": "code",
        "outputId": "3adb4594-110f-4841-f9f6-46829f7d9685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "scores = []\n",
        "test=[]\n",
        "s=0\n",
        "for train, val in kfold.split(list(zip(*train_gen)), train_label):\n",
        "  model.fit(unpack(*train_gen,train),train_label[train],batch_size=4,epochs=5,verbose=2,\n",
        "            validation_data=(unpack(*train_gen,val), train_label[val]))\n",
        "   \n",
        "\n",
        "  y_pred = model.predict(unpack(*train_gen,val), batch_size=4, verbose=1)\n",
        "\n",
        "  test.append(model.predict(test_gen, batch_size=4, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(train_label[val], y_pred, average='macro')\n",
        "  s+=1\n",
        "  print(s,' f1 score  is ',f1)\n",
        "  scores.append(f1)\n",
        "  tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3520 samples, validate on 880 samples\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6sF97LYki-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTtHl4Cr_lZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmE8SobV94Ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB7-YBgh9XqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI5T_a3y8niM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}