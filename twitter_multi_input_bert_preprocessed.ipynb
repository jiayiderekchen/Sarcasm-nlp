{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi_input_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM5U1HrV8AhzvO5KINzfske",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/Sarcasm-nlp/blob/master/twitter_multi_input_bert_preprocessed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEyCb5A6ZJPE",
        "colab_type": "code",
        "outputId": "da45e011-1254-4a20-b273-1295e1d4bf87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhD0ja60eRrW",
        "colab_type": "code",
        "outputId": "0efd942f-97b6-410a-9b3a-fd1899528335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        }
      },
      "source": [
        "!pip install tensorflow==2.1.0\n",
        "!pip install sentencepiece\n",
        "!pip install tensorflow-hub\n",
        "!pip install tensorflow-addons\n",
        "#!wget --quiet https://raw.githubusercontent.com/google-research/ALBERT/master/tokenization.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.1.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.17.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (45.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.85)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.17.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (45.2.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (0.8.3)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7gSHuuqaERd",
        "colab_type": "code",
        "outputId": "1cf1b0e1-a604-4221-beed-58574fd3bb32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/dataset/sarcasm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset/sarcasm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9gGhXLcaW2Y",
        "colab_type": "code",
        "outputId": "9dc00840-b2f9-4882-c04b-d5351d0357b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_gru.png\n",
            "\u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
            "sarcasm_detection_shared_task_reddit_testing.jsonl\n",
            "sarcasm_detection_shared_task_reddit_training.jsonl\n",
            "sarcasm_detection_shared_task_twitter_testing.jsonl\n",
            "sarcasm_detection_shared_task_twitter_training.jsonl\n",
            "tokenization.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_XH_TQ3f3dt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "43e5cce6-db93-4d2b-932b-82a00881047f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsQon6CBaXdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_train=pd.read_json('sarcasm_detection_shared_task_twitter_training.jsonl',lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYd47uZga3Z4",
        "colab_type": "code",
        "outputId": "c2fac726-51b7-4e60-8eab-25d479783fa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "twitter_train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n",
              "      <td>[A minor child deserves privacy and should be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER trying to protest about . Talking ...</td>\n",
              "      <td>[@USER @USER Why is he a loser ? He's just a P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER @USER He makes an insane about of ...</td>\n",
              "      <td>[Donald J . Trump is guilty as charged . The e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER Meanwhile Trump won't even release...</td>\n",
              "      <td>[Jamie Raskin tanked Doug Collins . Collins lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n",
              "      <td>[Man ... y ’ all gone “ both sides ” the apoca...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                            context\n",
              "0  SARCASM  ...  [A minor child deserves privacy and should be ...\n",
              "1  SARCASM  ...  [@USER @USER Why is he a loser ? He's just a P...\n",
              "2  SARCASM  ...  [Donald J . Trump is guilty as charged . The e...\n",
              "3  SARCASM  ...  [Jamie Raskin tanked Doug Collins . Collins lo...\n",
              "4  SARCASM  ...  [Man ... y ’ all gone “ both sides ” the apoca...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9jeCHvobEHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_train['response']=twitter_train['response'].str.replace('@USER', \"\") \n",
        "twitter_train['response']=twitter_train['response'].str.replace('\\d+', '')\n",
        "twitter_train['response']=twitter_train['response'].str.lower()\n",
        "twitter_train['response']=twitter_train['response'].str.replace('[^\\w\\s]','')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVRY4qxwckM7",
        "colab_type": "code",
        "outputId": "44c7db4a-c168-4580-b9f5-df5b23ee1244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "twitter_train.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>i dont get this  obviously you do care or y...</td>\n",
              "      <td>[A minor child deserves privacy and should be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>trying to protest about  talking about him a...</td>\n",
              "      <td>[@USER @USER Why is he a loser ? He's just a P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>he makes an insane about of money from the ...</td>\n",
              "      <td>[Donald J . Trump is guilty as charged . The e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>meanwhile trump wont even release his sat sc...</td>\n",
              "      <td>[Jamie Raskin tanked Doug Collins . Collins lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>pretty sure the antilincoln crowd claimed th...</td>\n",
              "      <td>[Man ... y ’ all gone “ both sides ” the apoca...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                            context\n",
              "0  SARCASM  ...  [A minor child deserves privacy and should be ...\n",
              "1  SARCASM  ...  [@USER @USER Why is he a loser ? He's just a P...\n",
              "2  SARCASM  ...  [Donald J . Trump is guilty as charged . The e...\n",
              "3  SARCASM  ...  [Jamie Raskin tanked Doug Collins . Collins lo...\n",
              "4  SARCASM  ...  [Man ... y ’ all gone “ both sides ” the apoca...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09EVo02McTQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_train['context']=twitter_train['context'].apply(lambda x: ','.join(map(str, x)))\n",
        "twitter_train['context']=twitter_train['context'].str.replace('@USER', \"\") \n",
        "twitter_train['context']=twitter_train['context'].str.lower()\n",
        "twitter_train['context']=twitter_train['context'].str.replace('[^\\w\\s]','')\n",
        "twitter_train['context']=twitter_train['context'].str.replace('\\d+', '')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM581aywcU06",
        "colab_type": "code",
        "outputId": "a4b3b7f9-194d-41dc-df10-d62250a0118f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "twitter_train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>i dont get this  obviously you do care or y...</td>\n",
              "      <td>a minor child deserves privacy and should be k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>trying to protest about  talking about him a...</td>\n",
              "      <td>why is he a loser  hes just a press secretar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>he makes an insane about of money from the ...</td>\n",
              "      <td>donald j  trump is guilty as charged  the evid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>meanwhile trump wont even release his sat sc...</td>\n",
              "      <td>jamie raskin tanked doug collins  collins look...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>pretty sure the antilincoln crowd claimed th...</td>\n",
              "      <td>man  y  all gone  both sides  the apocalypse o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                            context\n",
              "0  SARCASM  ...  a minor child deserves privacy and should be k...\n",
              "1  SARCASM  ...    why is he a loser  hes just a press secretar...\n",
              "2  SARCASM  ...  donald j  trump is guilty as charged  the evid...\n",
              "3  SARCASM  ...  jamie raskin tanked doug collins  collins look...\n",
              "4  SARCASM  ...  man  y  all gone  both sides  the apocalypse o...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAzapEnwcHPK",
        "colab_type": "code",
        "outputId": "0308a0f0-d142-4d16-db94-a1cd1ead48b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(twitter_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOggGwl_tzyF",
        "colab_type": "code",
        "outputId": "b219c516-11d6-4bba-ba15-be1f35698603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from collections import Counter\n",
        "Counter(twitter_train['label'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'NOT_SARCASM': 2500, 'SARCASM': 2500})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPlJPrRQsUnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "train_label=le.fit_transform(twitter_train['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biiLuJCUJMQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yGAL4yBvOQo",
        "colab_type": "code",
        "outputId": "13f6d139-46a6-4b3a-8217-4c47888ab3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "twitter_test=pd.read_json('sarcasm_detection_shared_task_twitter_testing.jsonl',lines=True)\n",
        "twitter_test.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>response</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Well now that ’ s problematic AF &lt;URL&gt;, @USER...</td>\n",
              "      <td>@USER @USER @USER My 3 year old , that just fi...</td>\n",
              "      <td>twitter_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Last week the Fake News said that a section o...</td>\n",
              "      <td>@USER @USER How many verifiable lies has he to...</td>\n",
              "      <td>twitter_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@USER Let ’ s Aplaud Brett When he deserves i...</td>\n",
              "      <td>@USER @USER @USER Maybe Docs just a scrub of a...</td>\n",
              "      <td>twitter_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Women generally hate this president . What's ...</td>\n",
              "      <td>@USER @USER is just a cover up for the real ha...</td>\n",
              "      <td>twitter_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Dear media Remoaners , you excitedly sharing ...</td>\n",
              "      <td>@USER @USER @USER The irony being that he even...</td>\n",
              "      <td>twitter_5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ...         id\n",
              "0  [Well now that ’ s problematic AF <URL>, @USER...  ...  twitter_1\n",
              "1  [Last week the Fake News said that a section o...  ...  twitter_2\n",
              "2  [@USER Let ’ s Aplaud Brett When he deserves i...  ...  twitter_3\n",
              "3  [Women generally hate this president . What's ...  ...  twitter_4\n",
              "4  [Dear media Remoaners , you excitedly sharing ...  ...  twitter_5\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0QlWiTlvblr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_test['response']=twitter_test['response'].str.replace('@USER', \"\") \n",
        "twitter_test['response']=twitter_test['response'].str.replace('\\d+', '')\n",
        "twitter_test['response']=twitter_test['response'].str.lower()\n",
        "twitter_test['response']=twitter_test['response'].str.replace('[^\\w\\s]','')\n",
        "twitter_test['context']=twitter_test['context'].apply(lambda x: ','.join(map(str, x)))\n",
        "twitter_test['context']=twitter_test['context'].str.replace('@USER', \"\") \n",
        "twitter_test['context']=twitter_test['context'].str.lower()\n",
        "twitter_test['context']=twitter_test['context'].str.replace('[^\\w\\s]','')\n",
        "twitter_test['context']=twitter_test['context'].str.replace('\\d+', '')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDjQfkKFvmKE",
        "colab_type": "code",
        "outputId": "44cf2fce-423e-48a2-cd6b-05f8164ce03e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "twitter_test.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>response</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>well now that  s problematic af url  my  year ...</td>\n",
              "      <td>my  year old  that just finished reading ni...</td>\n",
              "      <td>twitter_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>last week the fake news said that a section of...</td>\n",
              "      <td>how many verifiable lies has he told now   d...</td>\n",
              "      <td>twitter_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>let  s aplaud brett when he deserves it he co...</td>\n",
              "      <td>maybe docs just a scrub of a coach  i mean ...</td>\n",
              "      <td>twitter_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>women generally hate this president  whats up ...</td>\n",
              "      <td>is just a cover up for the real hate inside ...</td>\n",
              "      <td>twitter_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dear media remoaners  you excitedly sharing cl...</td>\n",
              "      <td>the irony being that he even has to ask why</td>\n",
              "      <td>twitter_5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ...         id\n",
              "0  well now that  s problematic af url  my  year ...  ...  twitter_1\n",
              "1  last week the fake news said that a section of...  ...  twitter_2\n",
              "2   let  s aplaud brett when he deserves it he co...  ...  twitter_3\n",
              "3  women generally hate this president  whats up ...  ...  twitter_4\n",
              "4  dear media remoaners  you excitedly sharing cl...  ...  twitter_5\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3jSGCzcijVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyXde76bikCX",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WryQV1NJilnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Thanks to https://www.kaggle.com/rftexas/text-only-kfold-bert\n",
        "def clean_tweets(tweet):\n",
        "    \"\"\"Removes links and non-ASCII characters\"\"\"\n",
        "    \n",
        "    tweet = ''.join([x for x in tweet if x in string.printable])\n",
        "    \n",
        "    # Removing URLs\n",
        "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
        "    \n",
        "    return tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgOkFxu5imYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Thanks to https://www.kaggle.com/rftexas/text-only-kfold-bert\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS1KqQXeisy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuations(text):\n",
        "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
        "    \n",
        "    for p in punctuations:\n",
        "        text = text.replace(p, f' {p} ')\n",
        "\n",
        "    text = text.replace('...', ' ... ')\n",
        "    \n",
        "    if '...' not in text:\n",
        "        text = text.replace('..', ' ... ')\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr3KV87livbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abbreviations = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"€\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\", \n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "    \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\", \n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\n",
        "    \"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retweet\", \n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retweet\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "    \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\", \n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJbuubtdi1FE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Thanks to https://www.kaggle.com/rftexas/text-only-kfold-bert\n",
        "def convert_abbrev(word):\n",
        "    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKzwXvAni2vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_abbrev_in_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [convert_abbrev(word) for word in tokens]\n",
        "    text = ' '.join(tokens)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgxagdlXjDIx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "0411cd38-ec26-4704-df50-4ab995ff6617"
      },
      "source": [
        "twitter_train.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>i dont get this  obviously you do care or y...</td>\n",
              "      <td>a minor child deserves privacy and should be k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>trying to protest about  talking about him a...</td>\n",
              "      <td>why is he a loser  hes just a press secretar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>he makes an insane about of money from the ...</td>\n",
              "      <td>donald j  trump is guilty as charged  the evid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>meanwhile trump wont even release his sat sc...</td>\n",
              "      <td>jamie raskin tanked doug collins  collins look...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>pretty sure the antilincoln crowd claimed th...</td>\n",
              "      <td>man  y  all gone  both sides  the apocalypse o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                            context\n",
              "0  SARCASM  ...  a minor child deserves privacy and should be k...\n",
              "1  SARCASM  ...    why is he a loser  hes just a press secretar...\n",
              "2  SARCASM  ...  donald j  trump is guilty as charged  the evid...\n",
              "3  SARCASM  ...  jamie raskin tanked doug collins  collins look...\n",
              "4  SARCASM  ...  man  y  all gone  both sides  the apocalypse o...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwnXMy3hi4wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_train[\"response\"] = twitter_train[\"response\"].apply(lambda x: clean_tweets(x))\n",
        "twitter_train[\"context\"] = twitter_train[\"context\"].apply(lambda x: clean_tweets(x))\n",
        "\n",
        "twitter_train[\"response\"] = twitter_train[\"response\"].apply(lambda x: remove_emoji(x))\n",
        "twitter_train[\"context\"] = twitter_train[\"context\"].apply(lambda x: remove_emoji(x))\n",
        "\n",
        "twitter_train[\"response\"] = twitter_train[\"response\"].apply(lambda x: remove_punctuations(x))\n",
        "twitter_train[\"context\"] = twitter_train[\"context\"].apply(lambda x: remove_punctuations(x))\n",
        "\n",
        "twitter_train[\"response\"] = twitter_train[\"response\"].apply(lambda x: convert_abbrev_in_text(x))\n",
        "twitter_train[\"context\"] = twitter_train[\"context\"].apply(lambda x: convert_abbrev_in_text(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w2REMLAj6vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_test[\"response\"] = twitter_test[\"response\"].apply(lambda x: clean_tweets(x))\n",
        "twitter_test[\"context\"] = twitter_test[\"context\"].apply(lambda x: clean_tweets(x))\n",
        "\n",
        "twitter_test[\"response\"] = twitter_test[\"response\"].apply(lambda x: remove_emoji(x))\n",
        "twitter_test[\"context\"] = twitter_test[\"context\"].apply(lambda x: remove_emoji(x))\n",
        "\n",
        "twitter_test[\"response\"] = twitter_test[\"response\"].apply(lambda x: remove_punctuations(x))\n",
        "twitter_test[\"context\"] = twitter_test[\"context\"].apply(lambda x: remove_punctuations(x))\n",
        "\n",
        "twitter_test[\"response\"] = twitter_test[\"response\"].apply(lambda x: convert_abbrev_in_text(x))\n",
        "twitter_test[\"context\"] = twitter_test[\"context\"].apply(lambda x: convert_abbrev_in_text(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFbszoOYjtpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeUv0qJZjcWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq6ibth_et3B",
        "colab_type": "text"
      },
      "source": [
        "#BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKg0eLmGfIgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTY8IMwEeuHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YloclZrLfKGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tokenization\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYNcCmz98egZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " max_len=256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmshsKHZfQfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_response = bert_encode(twitter_train.response, tokenizer, max_len=max_len)\n",
        "train_context = bert_encode(twitter_train.context, tokenizer, max_len=max_len)\n",
        "train_labels=twitter_train.label.values\n",
        "#test_input = bert_encode(test_bert.values, tokenizer, max_len=160)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuY1n_7FJQFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwNIe3UVvZJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_response = bert_encode(twitter_test.response, tokenizer, max_len=max_len)\n",
        "test_context = bert_encode(twitter_test.context, tokenizer, max_len=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Kik3pDvylj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen=[test_context[0],test_context[1],test_context[2],test_response[0],test_response[1],test_response[2]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VJSYpA7fByZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epLdmX34iQBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,concatenate,Dense,GlobalAveragePooling1D,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dunR1CHuexd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contex_input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"contex_input_word_ids\")\n",
        "contex_input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"contex_input_mask\")\n",
        "contex_segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"contex_segment_ids\")\n",
        "_, context_sequence_output = bert_layer([contex_input_word_ids, contex_input_mask, contex_segment_ids])\n",
        "context_clf_output = context_sequence_output[:, 0, :]\n",
        "\n",
        "\n",
        "reponse_input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_input_word_ids\")\n",
        "reponse_input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_input_mask\")\n",
        "reponse_segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"reponse_segment_ids\")\n",
        "_, reponset_sequence_output = bert_layer([reponse_input_word_ids, reponse_input_mask, reponse_segment_ids])\n",
        "reponset_clf_output = reponset_sequence_output[:, 0, :]\n",
        "\n",
        "\n",
        "\n",
        "conc=concatenate([context_clf_output,reponset_clf_output])\n",
        "#conc=Dropout(0.3)(conc)\n",
        "out = Dense(1, activation='sigmoid')(conc)\n",
        "    \n",
        "model = Model(inputs=[contex_input_word_ids, contex_input_mask, contex_segment_ids,reponse_input_word_ids,reponse_input_mask,reponse_segment_ids], outputs=out)\n",
        "model.compile(Adam(1e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJKok855k0F3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen=[train_context[0],train_context[1],train_context[2],train_response[0],train_response[1],train_response[2]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAYQgAvPAKhh",
        "colab_type": "code",
        "outputId": "76d0163c-b533-41ee-aa61-901044987189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_history = model.fit(\n",
        "    train_gen, train_label,\n",
        "    epochs=3,\n",
        "    batch_size=6,\n",
        "    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlq0hdlXKBUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(train_gen),len(train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf6e6w0nMTbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_context[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu3g2_VNIfwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tensorflow_addons as tfa\n",
        "# from sklearn.model_selection import StratifiedKFold\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfyQCuF6LxQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def unpack(a, b, c, d,e,f,g): \n",
        "#     #print(a[g].shape, b[g].shape, c[g].shape, d[g].shape,e[g].shape,f[g].shape) \n",
        "#     return [a[g], b[g], c[g], d[g],e[g],f[g]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuqQzXKYPIdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unpack(*train_gen,train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN_y6uqgX3pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ijzrJELIq5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import StratifiedKFold\n",
        "# kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "# scores = []\n",
        "# test=[]\n",
        "# s=0\n",
        "# for train, val in kfold.split(list(zip(*train_gen)), train_label):\n",
        "#   model.fit(unpack(*train_gen,train),train_label[train],batch_size=6,epochs=5,verbose=2,\n",
        "#             validation_data=(unpack(*train_gen,val), train_label[val]))\n",
        "   \n",
        "\n",
        "#   y_pred = model.predict(unpack(*train_gen,val), batch_size=6, verbose=1)\n",
        "\n",
        "#   test.append(model.predict(test_gen, batch_size=6, verbose=1).ravel())\n",
        "\n",
        "#   y_pred = (y_pred > 0.5)\n",
        "#   f1=f1_score(train_label[val], y_pred, average='macro')\n",
        "#   s+=1\n",
        "#   print(s,' f1 score  is ',f1)\n",
        "#   scores.append(f1)\n",
        "#   tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehh9grJZenEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=model.predict(test_gen, batch_size=6, verbose=1).ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NX6SVKPer5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6sF97LYki-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "sub=test.round()\n",
        "sub=le.inverse_transform(sub.ravel().astype('int16'))\n",
        "sub=pd.DataFrame(sub,columns=['label'])\n",
        "sub=pd.concat([twitter_test['id'], sub], axis=1)\n",
        "sub.head()\n",
        "sub.to_csv('/content/answer.txt',sep=',',index=False,header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTtHl4Cr_lZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmE8SobV94Ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB7-YBgh9XqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI5T_a3y8niM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}